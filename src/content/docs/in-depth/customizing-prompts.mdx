---
title: Customizing Prompts
description: Customizing prompts for transformers
sidebar:
  order: 6
---

Implementers of the trait `SimplePrompt` take a `Prompt` as argument. A `Prompt` references a `PromptTemplate` and can render, with optional context, to something that goes to an LLM.

:::warn
Avoid creating **compiled** templates during a pipeline or under load. The repository is managed internally by a `RwLock` and this _will_ deadlock.
:::

## Customizing templates

Templates use `tera` under the hood and can be fully customized.

For example:

```rust
let template = PromptTemplate::try_compiled_from_str("hello {{world}}").await?;
let transformer = MetadataQACode::builder().client(...).prompt_template(template).build()?;
```

When querying, templates are converted to prompts, have their context added, and are then send to the client.

By default, Swiftide transformers have the full `Node` available as context, and any other values the transformer provides.

## Ad-hoc templates

Prompts can also be constructed ad-hoc from a `&str` or `String`, with optional context.

```rust
let prompt: Prompt = "hello {{world}}".into();

openai.prompt(prompt.with_context_value("world", "swiftide")).await?;

```

## Bring your own

The prompt repository can also be extended with your own tera instance. This can be useful if you have your own templates
in markdown, or other functionality you would like to add.

You can also overwrite all the default prompts this way, by overwriting the template names.

**See the api documentation for more details and examples.**
